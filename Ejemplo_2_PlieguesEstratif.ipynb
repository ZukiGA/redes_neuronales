{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VpHL2MQRNlD"
   },
   "source": [
    "# Validación cruzada\n",
    "\n",
    "## Asignación estratificada aleatoria (ejemplo con dos clases), construccion manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer los datos, nombre de los atributos y la clase\n",
    "setInicial=pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age'], dtype='object')\n",
      "0    tested_positive\n",
      "1    tested_negative\n",
      "Name: class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "atributosName=setInicial.columns[:-1]\n",
    "atributoClase=setInicial.columns[-1]\n",
    "clasesName=setInicial[setInicial.columns[-1]].drop_duplicates()\n",
    "print(atributosName)\n",
    "print(clasesName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determinar el número de pliegues\n",
    "K_folds=3\n",
    "\n",
    "#Genera una columna con un número aleatorio\n",
    "setInicial['Tmp']=pd.DataFrame(np.random.rand(len(setInicial), 1))\n",
    "\n",
    "#Separar el conjunto de acuerdo a las clases, además se ordenan por\n",
    "#medio del atributo aleatorio para separarlos más adelante\n",
    "Positivos=setInicial[setInicial['class']=='tested_positive'].sort_values(by='Tmp')\n",
    "Positivos.pop('Tmp')\n",
    "Negativos=setInicial[setInicial['class']=='tested_negative'].sort_values(by='Tmp')\n",
    "Negativos.pop('Tmp')\n",
    "\n",
    "#Calcular el número de instancias por pliegue\n",
    "NumPositivos=int(len(Positivos)/K_folds)\n",
    "NumNegativos=int(len(Negativos)/K_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90Pk0MbHRFSl",
    "outputId": "25becbfa-699a-4943-ac8d-c3f69f065f6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pliegue:  1\n",
      "Train:  513  intancias.\n",
      "Test:  255  instancias.\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "tested_positive       0.65      0.51      0.57        89\n",
      "tested_negative       0.76      0.86      0.81       166\n",
      "\n",
      "       accuracy                           0.73       255\n",
      "      macro avg       0.71      0.68      0.69       255\n",
      "   weighted avg       0.72      0.73      0.72       255\n",
      "\n",
      "Pliegue:  2\n",
      "Train:  513  intancias.\n",
      "Test:  255  instancias.\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "tested_positive       0.66      0.55      0.60        89\n",
      "tested_negative       0.78      0.85      0.81       166\n",
      "\n",
      "       accuracy                           0.75       255\n",
      "      macro avg       0.72      0.70      0.71       255\n",
      "   weighted avg       0.74      0.75      0.74       255\n",
      "\n",
      "Pliegue:  3\n",
      "Train:  510  intancias.\n",
      "Test:  258  instancias.\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "tested_positive       0.74      0.43      0.55        90\n",
      "tested_negative       0.75      0.92      0.83       168\n",
      "\n",
      "       accuracy                           0.75       258\n",
      "      macro avg       0.74      0.68      0.69       258\n",
      "   weighted avg       0.75      0.75      0.73       258\n",
      "\n",
      "0.748062015503876 0.7421644626842986 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clasificador = MLPClassifier(solver='lbfgs', \n",
    "                    alpha=1e-5,\n",
    "                    hidden_layer_sizes=(8), \n",
    "                    random_state=42)\n",
    "\n",
    "#En cada iteración se genera un train y test\n",
    "contPos=0\n",
    "contNeg=0\n",
    "f1=[]\n",
    "\n",
    "for x in range(1,K_folds+1,1):\n",
    "    print(\"Pliegue: \",x)\n",
    "\n",
    "    if x==K_folds:\n",
    "        TopePos=len(Positivos)\n",
    "        TopeNeg=len(Negativos)\n",
    "    else:\n",
    "        TopePos=contPos+NumPositivos\n",
    "        TopeNeg=contNeg+NumNegativos\n",
    "\n",
    "    #Generar el train de acuerdo a los índices de cada pliegue\n",
    "    Test = pd.concat([Positivos.iloc[contPos:TopePos],Negativos.iloc[contNeg:TopeNeg]],axis=0)\n",
    "    #Generar el test, tomando como referencia los índices que no aparecen en el train\n",
    "    Training = pd.concat([Positivos.iloc[0:contPos],Positivos.iloc[TopePos:len(Positivos)],\n",
    "                          Negativos.iloc[0:contNeg],Negativos.iloc[TopeNeg:len(Negativos)]],axis=0)\n",
    "    \n",
    "    print(\"Train: \",len(Training),\" intancias.\\nTest: \",len(Test),\" instancias.\")\n",
    "    contPos+=NumPositivos\n",
    "    contNeg+=NumNegativos\n",
    "\n",
    "    #A PARTIR DE AQUÍ DE INICIA CON LA SEPARACIÓN Y CLASIFICACIÓN\n",
    "    valoresTrain = Training[atributosName]\n",
    "    valoresTest = Test[atributosName]\n",
    "    clasesTrain = Training[atributoClase]\n",
    "    clasesTest = Test[atributoClase]\n",
    "\n",
    "    ################## Modelo ###########################\n",
    "    modelo = clasificador.fit(valoresTrain, clasesTrain)\n",
    "\n",
    "    ################## Clasificar  #################\n",
    "    predict = modelo.predict(valoresTest)\n",
    "\n",
    "    ############ Evaluar ###############################\n",
    "    reporte=classification_report(clasesTest, predict, labels=clasesName, output_dict=True)\n",
    "    reporte2=classification_report(clasesTest, predict, labels=clasesName)#, output_dict=True)\n",
    "    print(reporte2)\n",
    "    f1.append(reporte['accuracy'])\n",
    "    \n",
    "print(max(f1),sum(f1)/len(f1),min(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
